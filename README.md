panfish
=======

Multicluster job submission 

Since there are a lot of unknowns in this work a lot of prototype code will be
written with each version increasing functionality or testing another aspect
of the system.  The versions below known as phases will correspond to directories
within this source tree.  For instance, phase 1 below will have a directory named
p1 



Phase 1 aka p1
=======

In this phase shadowp1.sh will assume all data has been staged and all
directories necessary have been created.  The shadowp1.sh script will merely
correctly set all SHADOW_ environments and submit the job correctly to
the cluster corresponding to the queue the shadowp1.sh is running under.  The
script will then wait for the job to complete

Phase 1 lessons
===============

 Well this step was easier then I thought it would be.  Was able to use SGE to 
schedule jobs to an available cluster by using SGE queues and setting a limit to
number of concurrent jobs.  Immediately see an issue with phase 1 approach where
we will overwhelm the remote clusters with ssh calls from each job requesting status.
Also saw I could use sge array jobs to lower impact on local SGE instance.  


Phase 2
=========
 
 In this phase take shadowp1.sh and adjust slightly to submit jobs by creating file
in a special directory.  The shadow script then monitors that file for job status.
This should scale to hundreds if not thousands of jobs.  Long term might want to
support multiple types of central storage mechanisms.  Beanstalkd, database, etc..

Phase 3
=========

Write simple perl daemon whose job is to take the files generated by previous shadowp1.5.sh
and submit them to remote clusters updating status when complete or failed.  

Phase 4
=======

In this phase scripts will be written to setup remote directories and stage
files on various clusters in a direct fashion.  This may not scale so we
may need to address an alternate solution later on.

Phase 5
=======

Adjust blast to use shadow system to run jobs on different clusters

Phase 6
=======

Check scalability.  It may require that transfers be throttled to not
overwhelm the local and remote filesystems and machines.


