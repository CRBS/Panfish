#!/usr/bin/perl


use Cwd;

use FindBin qw($Bin);

#these allow this script to work when installed in alternate path
use lib "$Bin/perl5";
use lib "$Bin/../share/perl5";


use Getopt::Long;
use Pod::Usage;

use Panfish::ForkExecutor;
use Panfish::PanfishConfig;
use Panfish::Logger;
use Panfish::FileReaderWriterImpl;
use Panfish::PanfishConfigFactory;
use Panfish::FileUtil;
use Panfish::FileJobDatabase;
use Panfish::JobState;
use Panfish::Job;

if (@ARGV == 0){
  pod2usage(2);
}


my $cmdLineParseResult = GetOptions ("q=s"        => \$qArgValue,
                                     "t=s"        => \$tArgValue,
                                     "taskfile=s" => \$taskFileArgValue,
                                     "e=s"        => \$eArgValue,
                                     "o=s"        => \$oArgValue,
                                     "N=s"        => \$nArgValue,
                                     "A=s"        => \$aArgValue,
                                     "walltime=s" => \$wallTimeArgValue,
                                     "sync=s"     => \$syncArgValue,
                                     "retry=i"    => \$retryArgValue,
                                     "batchfactor=s"    => \$batchFactorArgValue,
                                     "listclusters"     => \$listClustersArg,
                                     "writeoutputlocal" => \$writeOutputLocalArg,
                                     "stdintodb"  => \$stdInToDb,
                                     "verbose+"   => \$verboseArg,
                                     "noshadow"   => \$noShadowArg,
                                     "help|?"     => \$helpArg,
                                     "man"        => \$manArg) or pod2usage(2);


if ($helpArg){
  pod2usage(1);
}

if ($manArg){
  pod2usage(-exitstatus => 0, -verbose => 2);
}

# if --cluster is set then this
# call will be receiving jobs via stdin and
# those jobs need to be inserted into the 
# local database
if (defined($stdInToDb)){
  
  submitJobsFromStdInToCluster();
  exit(0);
}


if (@ARGV < 1 && !defined($listClustersArg)){
  pod2usage(2);
}



#only allow -t or --taskfile, but not both
if (defined($tArgValue) && defined($taskFileArgValue)){
  print STDERR "-t and --taskfile cannot both be defined\n";
  pod2usage(2);
}

# dont allow -sync y[es] with --taskfile argument
if (defined($taskFileArgValue) && 
    defined($syncArgValue) && 
    $syncArgValue =~/^[y|Y].*/){
  print STDERR "-sync $syncArgValue cannot be used with --taskfile parameter\n";
  pod2usage(2);
}

my $batchFactorArg = "";
if (defined($batchFactorArgValue)){
   $batchFactorArg = " --batchfactor $batchFactorArgValue";
}


my $command = "";
 
for (my $x = 0; $x < @ARGV; $x++){
   if ($command eq ""){
       $command = $ARGV[$x];
   }
   else {
      $command .= " $ARGV[$x]";  
   }
}

my $stderr = "";

my $stdout = "";

if (defined($eArgValue)){
   $stderr = " -e $eArgValue";
}

if (defined($oArgValue)){
   $stdout = " -o $oArgValue";
}

my $logger = Panfish::Logger->new();

# sets the logging level based on number of times verbose flag 
# was passed into command
$logger->setLevelBasedOnVerbosity($verboseArg);

my $readerWriter = Panfish::FileReaderWriterImpl->new($logger);
my $fUtil = Panfish::FileUtil->new($logger);
my $configFactory = Panfish::PanfishConfigFactory->new($readerWriter,$fUtil,$logger);
my $config = $configFactory->getPanfishConfig();
my $exec = Panfish::ForkExecutor->new();


# output the list of clusters panfish is configured with and exit
if (defined($listClustersArg)){
    print $config->getCommaDelimitedClusterList()."\n";
    exit(0);
}

# escape any $ for TASK_ID and JOB_ID
# also change TASK_ID to SGE_TASK_ID
$stderr=~s/\$TASK_ID/\\\$SGE_TASK_ID/g;
$stderr=~s/\$JOB_ID/\\\$JOB_ID/g;
$stdout=~s/\$TASK_ID/\\\$SGE_TASK_ID/g;
$stdout=~s/\$JOB_ID/\\\$JOB_ID/g;

my $timeout = 30;

my $tArgs = "";

my $newArgList = "-b y -cwd -notify";

if (defined($nArgValue)){
   $newArgList .= " -N $nArgValue";
}

if (defined($syncArgValue)){
   $newArgList .= " -sync $syncArgValue";
   if ($syncArgValue eq "y"){
      $timeout = undef;
   }
}

# lets build a new argument list for the qsub call
if (defined($tArgValue) || defined($taskFileArgValue)){
    $taskIdOutVar = ".\\\$TASK_ID.out";
}
else {
    $taskIdOutVar = ".out";
}

my $writeOutputLocal = "";
if (defined($writeOutputLocalArg)){
  $writeOutputLocal = " --writeoutputlocal";
}

# verify the list of queues specified is valid
#
my ($skippedClusters,$cList) = $config->getCommaDelimitedClusterList($qArgValue);
$logger->debug("Cluster list: $cList");
if (defined($skippedClusters)){
    $logger->warn("Ignoring these clusters since they are not in the configuration: $skippedClusters");
}

# Verify we got at least one queue otherwise bail
if ($cList eq ""){
   $logger->fatal("No queues specified to submit jobs to.  Please add queues to cluster.list parameter in configuration");
   exit(1);
}

$newArgList .= " -q ".$cList;

my $accountArg = " ";
if (defined($aArgValue)){
   $accountArg = " -A \"$aArgValue\"";
}

my $wallTimeArg = " ";
if (defined($wallTimeArgValue)){
   $wallTimeArg = " --walltime $wallTimeArgValue";
}

my $exitAfterSubmitArg = " ";
if (defined($noShadowArg)){
  $exitAfterSubmitArg = " --exitaftersubmit";
}

my $exitCode;

# generate -t argument array based on arguments passed in by the user
my @tArgArray = generateTArgumentArray($readerWriter,$logger,$tArgValue,$taskFileArgValue);

my $len = @tArgArray;
$logger->debug("Got $len jobs to submit");

my $lineStdOutPath;
if ($config->getLineStandardOutPath() eq "/dev/null"){
   $lineStdOutPath = $config->getLineStandardOutPath();
}
else {
   $lineStdOutPath = $config->getLineStandardOutPath()."/\\\$JOB_ID".$taskIdOutVar;
}


for (my $x = 0; $x < @tArgArray; $x++){

   $cmd = $config->getSubmit()." $tArgArray[$x] $newArgList -j y -o ".
          $lineStdOutPath." ".
          $config->getLineCommand().$exitAfterSubmitArg.$wallTimeArg.$accountArg.$stdout.$stderr.$batchFactorArg.$writeOutputLocal." -c \"'$command'\"";

    $logger->info("Running command: $cmd");

    $exitCode = $exec->executeCommand($cmd,$timeout);

    print $exec->getOutput();
    $logger->info("Exit Code:  ".$exitCode);
    if ($exitCode != 0){
      $logger->fatal("Error submitting job");
    }
}
exit($exitCode);


#
# Given -t parameters or --taskfile parameters generate
# an array of -t arguments to submit to qsub
#
sub generateTArgumentArray {
   my $readerWriter = shift;
   my $logger = shift;
   my $tArgValue = shift;
   my $taskFileArgValue = shift;

   my @tArgArray;

   # neither parameter is set so just push an empty string onto the
   # array and a regular single job will be submitted
   if (!defined($tArgValue) &&
       !defined($taskFileArgValue)){
     push(@tArgArray,"");
     return @tArgArray;
   }

   # if $tArgValue is defined just use that file and push one element
   # into array cause this is the standard way to submit a single array job
   if (defined($tArgValue)){
      push(@tArgArray,"-t $tArgValue");
      return @tArgArray;
   }

   # if $taskFileArgValue is set we need to open that file
   # sort the numbers in it and generate -t flags so that the
   # minimum # of submits is required.  The -t flag supports
   # n-m flag so if we have tasks 1,2,3,4,5 from the file we can
   # call -t 1-5 in a single call.
   if ( ! -e $taskFileArgValue ){
      $logger->fatal("$taskFileArgValue file does not exist");
      exit(1);
   }
 
   my $res = $readerWriter->openFile($taskFileArgValue);

   if (defined($res)){
      $logger->fatal("Error opening $taskFileArgValue : $res");
      exit(1);
   }

   #read contents of file and put into array
   my @ids;
   my $line = $readerWriter->read();
   while(defined($line)){
      chomp($line);
      push(@ids,$line);
      $line = $readerWriter->read();
   }
   $readerWriter->close();

   # sort array in numeric ascending order
   my @sortedIds = sort { $a <=> $b } @ids;
   
   my $startId = $sortedIds[0];
   my $curId = $startId;
   my $added = 0;
   for (my $x = 1; $x < @sortedIds; $x++){
        
         # if the next id is only 1 larger then the current
         # set $curId to that value
         # If the value is not one larger then
         # we need to add an entry to the tArgArray and 
         # set $startId to $sortedIds
         if ($curId+1 == $sortedIds[$x]){
             $curId = $sortedIds[$x];
         }
         else {
             push(@tArgArray,"-t ".$startId."-".$curId);
             $startId = $sortedIds[$x];
             $curId = $startId;
             
         }
   }

   push(@tArgArray,"-t ".$startId."-".$curId);
   
   return @tArgArray;
}


#
#
#
sub submitJobsFromStdInToCluster {

    my $logger = Panfish::Logger->new();

    my $logFileHandle = undef;

    my $fUtil = Panfish::FileUtil->new($logger);

    my $reader = Panfish::FileReaderWriterImpl->new($logger);
    my $configFactory = Panfish::PanfishConfigFactory->new($reader,$fUtil,$logger);
    my $config = $configFactory->getPanfishConfig();
    $logger->setLevelBasedOnVerbosity($config->getPanfishSubmitVerbosity());

    my $jobDb = Panfish::FileJobDatabase->new($reader,
                                         $config->getDatabaseDir(),$fUtil,$logger);

    my $job;
    my $line;
    my $jobId;
    my $taskId;

    my $exitVal = 0;
    my $jobName;
    my $jobNameWithUnderscore;
    my $cwd = getcwd();

    while(<STDIN>){
        chomp();
        $line = $_;
        # line should contain path to psub file
        # take this file and make a new job file using this as the command
        # write the command to a file using the job database
        # and print out the psub file minus .psub and path prefix.
        
        if ($line=~/^.*\/(.*)\.(.*)\.psub$/){
            $jobId = $1;
            $taskId = $2;
            $jobName = $jobId.".".$taskId;
        }
        else {
            $jobId = $line;
            $jobId=~s/^.*\///;
            $jobId=~s/\.psub//;
            $taskId = "";
            $jobName = $jobId;
        }
        $logger->debug("Job id: ".$jobName);
        $jobNameWithUnderscore = $jobName;
        $jobNameWithUnderscore=~s/\./_/g;

        $job = Panfish::Job->new($config->getThisCluster(),
                                 $jobId,
                                 $taskId,
                                 "X".$jobNameWithUnderscore,
                                 $cwd,
                                 undef,
                                 Panfish::JobState->BATCHEDANDCHUMMED(),
                                 0,
                                 undef,
                                 $line);

        my $res = $jobDb->insert($job);
        if (!defined($res)){
            print "$jobName\n";
        }
        else {
            $exitVal = 1;
            $logger->error("Unable to submit job $line : $res");
        }
    }

    exit($exitVal);
}

1;

__END__

=head1 NAME

panfishcast - Submit a job to Panfish Multicluster Grid Engine Wrapper

=head1 SYNOPSIS

panfishcast [ B<options (excluding --stdintodb)> ] [ B<command> ]

echo -e "1.1.job\\n2.2.job" | panfishcast --stdintodb

=head1 DESCRIPTION

B<Panfishcast> has two modes as shown above in the SYNOPSIS.  

In the first mode, used by users, B<panfishcast> submits jobs to Panfish 
Multicluster Grid Engine Wrapper which allows a script based serial 
B<command> to be run on a remote cluster. B<panfishcast> does this by a 
submission of a "shadow" job to the local Grid Engine.  Once started, 
the "shadow" job then handles running and monitoring of the actual 
B<command> on the remote cluster.  Upon B<command> completion the shadow 
job exits.  The caller of B<panfishcast> can monitor the status of their 
job by using B<qstat> on the id of the shadow jobs output from the 
B<panfishcast> call.

B<NOTE:>  It is the responsibility of the caller to invoke 
B<panfishland> to retrieve the data from the remote cluster once the 
job completes.

=head1 OPTIONS

B<Panfishcast> only implements a small subset of the options in B<qsub> 
which are described as follows.

=over 4

=item B<-A Account(s)>

Defines account(s) to set in remote cluster scheduler.  This parameter 
can be in two formats.  The basic format is just to set a single account 
string which will be set for all remote clusters.  The complex format 
goes with queue followed by two colons and then then account to use for 
that queue.  If more then one queue needs to be specified then use 
commas with no spaces to delimit.

Format:

<queue>::<account>,<queue>::<account>

Example:

foo.q::ddp555,blah.q::TG2342s

=item B<-N name>

The name of the job.  Allowed characters must conform to restrictions 
for B<-N> parameter in B<qsub>.

=item B<-t [-m[:s]]>

Submits an array job with the environment variable B<SGE_TASK_ID> set 
to index number of job.   

=item B<--taskfile path>

Submits task array jobs with ranges based on values in B<path> 
specified as an argument to this parameter.  This method assumes the 
file contains integers, one per line denoting task id's to submit.  
B<panfishcast> will first sort the values in this file and attempt to 
batch the jobs into as few submits as possible.  

Example file:

 1
 2
 3
 5
 6
 7

In the above file B<panfishcast> will submit two array jobs one with a 
range of 1-3 and another with a range of 5-7 (since 4 is not listed).  
The code does not check for duplicate ids and non numerical values in 
the file will have unknown consequences.  Also this flag cannot be used 
with B<-t> or B<-sync y[es]> flags.

=item B<-e path,...>

Defines path of standard error stream.  The following variables can be 
used in construction of the path and will be set appropriately:

=over 8

=item $USER       user ID of job owner

=item $JOB_ID     current job ID

=item $TASK_ID    array job task index number

Z<>

=back

=item B<-o path,...>

Defines path of standard output stream.  See B<-e> description for 
allowed variables in B<path>.


=item B<-q wc_queue_list>

Defines list of queues this job can run under (comma delimited).  The 
queues should correspond to valid "shadow" queues.

=item B<-sync y[es]|n[o]>

Works same as B<qsub>.  Causes B<panfishcast> to wait for the job to 
complete. 

=item B<--writeoutputlocal>

If set, directs users program to write stderr and stdout files to 
$PANFISH_SCRATCH folder naming them JOBID.TASKID.out/err.  When the 
users program completes the output files are copied to destination 
specified by B<-e> and B<-o> parameters.

=item B<--stdintodb>

Used internally by B<panfish> daemon.  Tells B<panfishcast> that this 
is an internal invocation that should take jobs given via standard in 
and insert them into the local panfish database.

=item B<--verbose>

Verbose mode.  Causes B<panfishcast> to print debugging messages.  
Multiple B<--verbose> increase verbosity.  The maximum is 2.

NOTE:  This is not an option in B<qsub>.

=item B<--noshadow>

Causes shadow jobs to exit immediately after submission into the 
B<panfish> database.  When using this option use B<panfishstat> to 
monitor job status.

=item B<--batchfactor factor(s)>

Defines a multiplier known as a batch job factor which causes jobs to 
be batched by X times on each node and run through in a serial fashion.  
This exists to reduce demand on schedulers for fast running jobs.  For 
example, if a compute node can run 8 jobs in parallel and a batch 
factor of 2 is set then a panfish job submitted to that compute node 
will be given 16 jobs to run in 8 jobs batches.  This multiplier also 
works for values less then 1, but greater then 0.  In this case the 
batchfactor reduces the number of concurrent jobs allowed to run per 
node.  For example, say a cluster runs 8 jobs on a node, if the 
B<batchfactor> is set to 0.5 then only 4 jobs will be batched and run 
concurrently on those nodes.  This parameter can be in two formats.  The 
basic format is just to set a single factor X which will be set for all 
remote clusters.  If more then one queue needs to be specified then use 
commas with no spaces to delimit.

Format:

 <queue>::<float X>,<queue>::<float X>

Example:

 foo.q::0.25,blah.q::0.5

=item B<--listclusters>

If defined B<panfishcast> will output the current cluster list in a 
comma delimited string and exit. 

=item B<--walltime HH:MM:SS>

Defines walltime to specify in hours:minutes:seconds for all remote clusters in the basic format. In
complex format walltime can be specified for each cluster by first listing the cluster followed
by two colons and then the walltime.  If multiple clusters need to be set then delimit with a
comma and no spaces.

Format:

<queue>::<HH:MM:SS>,<queue>::<HH:MM:SS>

Example:

foo.q::12:00:00,blah.q::08:00:00


=item B<command>

The job to run.  This B<command> must be a script file, its the last 
argument and must meet the following conditions:

=over 12

=item Any Grid Engine directives ie B<#$> in the B<command> script will 
be ignored.

Z<>

=item B<Command> must be a bash script invoking commands and tools that 
can be run on any of the remote clusters.

Z<>

=item B<Command> must use B<PANFISH_BASEDIR> variable to prefix any 
paths.  A list of all environment variables that will be set can be 
seen in the B<ENVIRONMENT VARIABLES> section below.

Z<>

=item B<Command> must NOT assume output from any other job enqueued or 
running in B<Panfish> will be available to it.

Z<>

=back

=back

=head1 ENVIRONMENT_VARIABLES

The following environment variables are set for B<command> run on remote 
clusters. 

Z<>

=over 16

=item PANFISH_SCRATCH_DIR   Path to temp directory.

=item PANFISH_BASEDIR      Base path of filesystem on remote clusters.  This should be
                           prefixed on all paths in script.

=item SGE_TASK_ID          Task ID of job.  If non array job is submitted this will be empty.

=back 

Z<>

=head1 RESTRICTIONS

B<Panfish> relies on environment variables to alias paths so all
paths refered by B<Command> must be relative or utilize B<ENVIRONMENT VARIABLES>
listed above.


=head1 EXIT STATUS

=over

=item 0     Operation was successful.

=item >0    Error.

=back

=head1 EXAMPLES

=head1 FILES

=head1 AUTHOR

Christopher Churas <churas@ncmir.ucsd.edu>

=head1 REPORTING BUGS



=head1 COPYRIGHT


=head1 SEE ALSO


=cut
