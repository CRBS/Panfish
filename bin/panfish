#!/usr/bin/perl

use FindBin qw($Bin);

#these allow this script to work when installed in alternate path
use lib "$Bin/perl5";
use lib "$Bin/../share/perl5";


use Getopt::Long;
use Pod::Usage;

use Panfish::ForkExecutor;
use Panfish::PanfishConfig;
use Panfish::Logger;
use Panfish::FileReaderWriterImpl;
use Panfish::PanfishConfigFactory;
use Panfish::FileJobDatabase;
use Panfish::JobBatcher;
use Panfish::FileUtil;
use Panfish::SSHExecutor;
use Panfish::RemoteIO;
use Panfish::JobBatchedChummer;
use Panfish::SSHJobSubmitter;
use Panfish::SSHJobWatcher;
use Panfish::QsubJobSubmitter;
use Panfish::QstatJobWatcher;
use Panfish::SubmitCommand;

use Panfish::PBSQsubParser;
use Panfish::SGEQsubParser;
use Panfish::SLURMSbatchParser;

use Panfish::JobHashFactory;
use Panfish::CurrentWorkingDirHashKeyGenerator;
use Panfish::PsubDirnameHashKeyGenerator;
use Panfish::PsubHashKeyGenerator;
use Panfish::PsubIdHashKeyGenerator;
use Panfish::FileLock;
use Panfish::SortByFileAgeSorter;
use Panfish::KilledJobHandler;
use Panfish::PsubFileFromJobsCreator;
use Panfish::CommandsFileFromJobsCreator;

#catch the term signal and set a variable which will cause code to
#leave while loop gracefully
$SIG{TERM} = sub { $SIGTERMCALLED = 1; print "Received TERM signal\n";};

#obtained from http://www.webreference.com/perl/tutorial/9/3.html
sub daemonize {
  chdir '/'                 or die "Can't chdir to /: $!";
  open STDIN, '/dev/null'   or die "Can't read /dev/null: $!";
  open STDOUT, '>>/dev/null' or die "Can't write to /dev/null: $!";
  open STDERR, '>>/dev/null' or die "Can't write to /dev/null: $!";
  defined(my $pid = fork)   or die "Can't fork: $!";
  exit if $pid;
  setsid                    or die "Can't start a new session: $!";
  umask 0;
}

my $cmdLineParseResult = GetOptions ("cron"        => \$cronArg,
                                     "help|?"       => \$helpArg,
                                     "man"          => \$manArg) 
                                     or pod2usage(2);

if ($helpArg){
  pod2usage(1);
}

if ($manArg){
  pod2usage(-exitstatus => 0, -verbose => 2);
}

my $logger = Panfish::Logger->new();

my $fUtil = Panfish::FileUtil->new($logger);

my $reader = Panfish::FileReaderWriterImpl->new($logger);
my $configFactory = Panfish::PanfishConfigFactory->new($reader,$fUtil,$logger);
my $config = $configFactory->getPanfishConfig();
$logger->setLevelBasedOnVerbosity($config->getPanfishVerbosity());

my $fileAgeSorter = Panfish::SortByFileAgeSorter->new($fUtil);
my $writer = Panfish::FileReaderWriterImpl->new($logger);
my $exec = Panfish::ForkExecutor->new();
my $sshExec = Panfish::SSHExecutor->new($config,$exec,$logger);

if ($config->getThisCluster() eq ""){
  $logger->fatal("this.cluster parameter not set in configuration");
  pod2usage(-exitstatus => 1, -verbose => 1);
}

my $clusterArgValue  = $config->getThisCluster();

my $scriptName = $0;
$scriptName=~s/^.*\///;
my $lockFile = $config->getDatabaseDir($clusterArgValue)."/".$scriptName;

$logger->debug("Looking for lock file $lockFile");
my $fLock = Panfish::FileLock->new($logger,$fUtil,$exec,$reader);
my $error = $fLock->create($lockFile,$$);
if (defined($error)){
  $logger->fatal("Unable to create lock file : $error");
  exit(1);
}

my $iterationArgValue = undef;
if (defined($cronArg)){
  $iterationArgValue = 1;
}

my $uploader = Panfish::RemoteIO->new($config,$sshExec,$logger,$fUtil);

my $jobDb = Panfish::FileJobDatabase->new($reader,$config->getDatabaseDir(),
                                          $fUtil,$logger);

my $curDirKeyGen = Panfish::CurrentWorkingDirHashKeyGenerator->new($logger);
my $curDirJobHashFac = Panfish::JobHashFactory->new($curDirKeyGen,$logger);

my $psubCreator = Panfish::PsubFileFromJobsCreator->new($config,$fUtil,$reader,
                                                        $writer,$logger);

my $cmdCreator = Panfish::CommandsFileFromJobsCreator->new($config,$fUtil,
                                                           $writer,$logger);

my $batcher = Panfish::JobBatcher->new($config,$jobDb,$logger,$cmdCreator,
                                       $psubCreator,$curDirJobHashFac,
                                       $fileAgeSorter);

my $psubKeyGen = Panfish::PsubHashKeyGenerator->new($logger,$fUtil);

my $psubDirKeyGen = Panfish::PsubDirnameHashKeyGenerator->new($logger,
                                                           $psubKeyGen,$fUtil);

my $psubDirJobHashFac = Panfish::JobHashFactory->new($psubDirKeyGen,$logger);

my $batchedChummer = Panfish::JobBatchedChummer->new($config,$jobDb,
                                                     $logger,$fUtil,$uploader,
                                                     $psubDirJobHashFac,
                                                     $fileAgeSorter);

my $psubJobHashFac = Panfish::JobHashFactory->new($psubKeyGen,$logger);

my $sshSubmitter = Panfish::SSHJobSubmitter->new($config,$jobDb,$logger,
                                                 $fUtil,$sshExec,
                                                 $psubJobHashFac,
                                                 $fileAgeSorter);

my $psubIdKeyGen = Panfish::PsubIdHashKeyGenerator->new($logger,$psubKeyGen);

my $psubIdJobHashFac = Panfish::JobHashFactory->new($psubIdKeyGen,$logger);

my $sshWatcher = Panfish::SSHJobWatcher->new($config,$jobDb,$logger,
                                       $fUtil,$sshExec,$psubIdJobHashFac);

# TODO: move this into a factory
my $sParser;
if ($config->getEngine() eq "SGE"){
  $sParser = Panfish::SGEQsubParser->new();
}
elsif ($config->getEngine() eq "PBS"){
  $sParser = Panfish::PBSQsubParser->new();
}
elsif ($config->getEngine() eq "SLURM"){
  $sParser = Panfish::SLURMSbatchParser->new();
}
else {
  $logger->fatal("Engine ".$config->getEngine(). " not supported");
  exit(1);
}

my $submitCommand = Panfish::SubmitCommand->new($logger,$exec,
                                                $config->getSubmit(),
                                                $sParser,60,3,60);

my $qsubSubmitter = Panfish::QsubJobSubmitter->new($config,$jobDb,$logger,
                                                   $fUtil,$submitCommand,
                                                   $psubJobHashFac,
                                                   $fileAgeSorter);

my $qstatWatcher = Panfish::QstatJobWatcher->new($config,$jobDb,$logger,
                                                 $fUtil,$exec);

my $killer = Panfish::KilledJobHandler->new($jobDb,$logger,$fUtil,$uploader);

my @clusterList;
my $error;

($error,@clusterList) = $config->getClusterListAsArray();

if (defined($error)){
  $logger->fatal("Problem getting cluster list : $error");
  $fUtil->removeLock("$0.lck");
  exit(1);
}

my $iterationCount = 1;

my $keepLooping = 1;

my $exitCode = 0;

# infinite loop broken only by signal or fatal error.
while($SIGTERMCALLED == 0 && $keepLooping == 1){
    
  for (my $x = 0; $x < @clusterList ; $x++){
    if ($logger->isDebugEnabled() && !defined($clusterArgValue)){
      $logger->debug("$clusterList[$x] --".
                     $jobDb->getSummaryForCluster($clusterList[$x]));
    }

    # Obtain updated statistics on cluster

    # Check for any jobs to be killed
    $check = $killer->removeKilledJobs($clusterList[$x]);
      
    $check = $batcher->batchJobs($clusterList[$x]);
      
    $check = $batchedChummer->chumBatchedJobs($clusterList[$x]);
      
    # if this is the local cluster so lets see if we have to 
    # directly submit any jobs and check the status of any
    # local real jobs
    # otherwise remotely submit and check on status of jobs
    if ($clusterArgValue eq $clusterList[$x]){
      $check = $qsubSubmitter->submitJobs($clusterList[$x]);
      $check = $qstatWatcher->checkJobs($clusterList[$x]);
    }
    else {
      $check = $sshSubmitter->submitJobs($clusterList[$x]);
      $check = $sshWatcher->checkJobs($clusterList[$x]);
    }
  }

  if (defined($iterationArgValue)){
    if ($iterationCount >= $iterationArgValue){
      $logger->debug("IterationCount $iterationCount equals or exceeds ".
                     "$iterationArgValue exiting..");
      $keepLooping = 0;
    }
  }
  if ($SIGTERMCALLED == 0 && $keepLooping == 1){
    $logger->debug("Sleeping ".$config->getPanfishSleepTime());
    sleep $config->getPanfishSleepTime();
  }
  $iterationCount++;
}

if ($SIGTERMCALLED == 1){
  $logger->info("Received Term signal exiting");
}

$logger->info("Exit Code:  ".$exitCode);
$fUtil->removeLock($lockFile);
exit($exitCode);
1;

__END__

=head1 NAME

panfish - Panfish Multicluster Submission System Daemon

=head1 SYNOPSIS

panfish [ B<options> ]

=head1 DESCRIPTION

Panfish enables jobs built for Sun Grid Engine/Open Grid Scheduler to 
run on multiple clusters in parallel utilizing tools similar to those
used to submit jobs to Sun Grid Engine/Open Grid Scheduler.  

=head1 OPTIONS

=over 4

=item B<--cron>

Runs B<panfish> in non daemon mode through one full iteration.

=back

=head1 EXIT STATUS

=over

=item 0     Operation was successful.

=item >0    Error.

=back

=head1 EXAMPLES

=head1 FILES

 hello

=head1 AUTHOR

Christopher Churas <churas@ncmir.ucsd.edu>

=head1 REPORTING BUGS

bugs


=head1 COPYRIGHT

blah blah

=head1 SEE ALSO

more blah



=cut
